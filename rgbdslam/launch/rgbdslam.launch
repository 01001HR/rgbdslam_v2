<!-- This file demonstrates the use of SIFT features for online SLAM with a Kinect.
     The openni driver has to be started seperately -->
<launch>
  <node pkg="rgbdslam" type="rgbdslam" name="rgbdslam" cwd="node" required="true" output="screen"> 
    <!-- Input data settings-->
    <param name="config/topic_image_mono"              value="/camera/rgb/image_rect_color"/> 
    <param name="config/topic_image_depth"             value="/camera/depth_registered/hw_registered/image_rect_raw"/>
    <param name="config/topic_points"                  value=""/> <!--if empty, poincloud will be reconstructed from image and depth -->

    <param name="config/feature_detector_type"         value="SIFTGPU"/>
    <param name="config/feature_extractor_type"        value="SIFTGPU"/>
    <param name="config/nn_distance_ratio"             value="0.95"/> <!-- Feature correspondence is valid if distance to nearest neighbour is smaller than this parameter times the distance to the 2nd neighbour -->
    <param name="config/max_keypoints"                 value="700"/>
    <param name="config/cloud_creation_skip_step"      value="4"/>
    <param name="config/subscriber_queue_size"         value="2"/>

    <!-- Algortithm settings -->
    <param name="config/backend_solver"                value="pcg"/> <!-- Which solver to use in g2o for matrix inversion: "csparse" , "cholmod" or "pcg"  -->

  </node>
</launch>
